# create kind cluster
kind create cluster --config ~/git/docker/kind-cluster/klc.yaml

# to delete cluster
kind delete cluster --name=klc

# shell into the control plane
docker exec -it klc-control-plane bash

# stop kind containers
docker stop $(docker ps -q --filter "name=klc")

# to start kind containers
docker start $(docker ps -aq --filter "name=klc")

# run these on the kind cluster
kubectl run nginx --image=nginx

kubectl get pods

kubectl logs pod/nginx

# get more pod info
kubectl get pods -o wide

# output
NAME    READY   STATUS    RESTARTS   AGE    IP           NODE          NOMINATED NODE   READINESS GATES
nginx   1/1     Running   0          115s   10.244.1.2   klc-worker2   <none>           <none>

# install ping on the control plane node to be able to ping pod IPs
apt update
apt install -y iputils-ping

# curl nginx in the pod
root@klc-control-plane:/# curl 10.244.1.2

# run port forward on the host machine to expose nginx in the pod to the host
# access http://127.0.0.1:8080/ in the browser
sysuser@ubuntudev:~/git/docker$ kubectl port-forward pod/nginx 8080:80

# curl can also be used to access nginx on the pod
sysuser@ubuntudev:~/git/docker$ curl localhost:8080

# run this on the control plane. this will start a curl pod which will curl the nginx pod and exit
kubectl run -it --rm curlpod --image=curlimages/curl --restart=Never -- 10.244.1.2

# run ubuntu pod in the background
kubectl run ubuntupod --image=ubuntu sleep infinity 

# shell into pod: ubuntu pod which is currently sleeping
kubectl exec -it ubuntupod -- bash

# run the following inside ubuntupod
ps -ef

# output
root@ubuntupod:/# ps -ef
UID          PID    PPID  C STIME TTY          TIME CMD
root           1       0  0 23:55 ?        00:00:00 sleep infinity
root          12       0  0 23:57 pts/0    00:00:00 bash
root          21      12  0 23:58 pts/0    00:00:00 ps -ef

# run from control plane pod # 

# delete both pods 
kubectl delete pod/nginx pod/ubuntupod --now

# we can use a dry run to output pod config  as a yaml and pipe it to a file using tee
kubectl run nginxpod --image=nginx --dry-run=client -o yaml | tee nginxpod.yaml

# use the create option to create the pod by specifying the yaml file
root@klc-control-plane:/# kubectl create -f nginxpod.yaml

# create ubuntu pod
root@klc-control-plane:/# kubectl run ubuntupod --image=ubuntu --dry-run=client -o yaml sleep infinity | tee ubuntupod.yaml

# create the pod. apply command can be used
root@klc-control-plane:/# kubectl apply -f ubuntupod.yaml 

# get the pods
root@klc-control-plane:/# kubectl get pods -o wide

# output
NAME        READY   STATUS    RESTARTS   AGE     IP           NODE          NOMINATED NODE   READINESS GATES
nginxpod    1/1     Running   0          4m51s   10.244.2.2   klc-worker2   <none>           <none>
ubuntupod   1/1     Running   0          22s     10.244.1.2   klc-worker    <none>           <none>

# we want to combine both the yaml files into one file called combined.yaml
# grep to make sure both the yaml files exist
root@klc-control-plane:/# ls -l | grep yaml

# output
root@klc-control-plane:/# ls -l | grep yaml
-rw-r--r--   1 root root  215 Jan 31 00:32 nginxpod.yaml
-rw-r--r--   1 root root  256 Jan 31 00:38 ubuntupod.yaml

# run the following
root@klc-control-plane:/# { cat nginxpod.yaml ; echo "---"; cat ubuntupod.yaml; } | tee combined.yaml

# run the grep command
root@klc-control-plane:/# ls -l | grep yaml

# output
root@klc-control-plane:/# ls -l | grep yaml
-rw-r--r--   1 root root  475 Jan 31 00:44 combined.yaml
-rw-r--r--   1 root root  215 Jan 31 00:32 nginxpod.yaml
-rw-r--r--   1 root root  256 Jan 31 00:38 ubuntupod.yaml

# apply the combined yaml
root@klc-control-plane:/# kubectl apply -f combined.yaml 

# delete the pods
root@klc-control-plane:/# kubectl delete -f combined.yaml --now


# copy mypod.yaml from host to controlplane container
sysuser@ubuntudev:~/git/docker/kind-cluster$ docker cp /home/sysuser/git/docker/kcna/kubernetes/mypod.yaml klc-control-plane:/mypod.yaml

# apply mypod.yaml to create the pod with two containers
root@klc-control-plane:/# kubectl apply -f mypod.yaml -all-namespaces

# this would show 2/2 under ready column because there are two containers running in the same pod
root@klc-control-plane:/# kubectl get pods -o wide
NAME    READY   STATUS    RESTARTS   AGE     IP           NODE         NOMINATED NODE   READINESS GATES
mypod   2/2     Running   0          3m36s   10.244.1.4   klc-worker   <none>           <none>


# get all the information about mypod
root@klc-control-plane:/# kubectl describe pod/mypod

# curl the shared ip address of mypod
root@klc-control-plane:/# kubectl run -it --rm curlpod --image=curlimages/curl --restart=Never -- 10.244.2.2

# output
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
pod "curlpod" deleted from default namespace

# to make sure the sidecar is doing what its supposed to, we can get the logs from the container in the pod
root@klc-control-plane:/# kubectl logs mypod -c ubuntu-sidecar

# create a crash file so that the side car would crash
root@klc-control-plane:/# kubectl exec -it mypod -c ubuntu-sidecar -- touch /tmp/crash

# get pod information
root@klc-control-plane:/# kubectl get pods -o wide
NAME    READY   STATUS   RESTARTS      AGE   IP           NODE         NOMINATED NODE   READINESS GATES
mypod   1/2     Error    2 (80s ago)   22m   10.244.2.5   klc-worker   <none>           <none>


root@klc-control-plane:/# kubectl get pods -o wide
NAME    READY   STATUS    RESTARTS      AGE   IP           NODE         NOMINATED NODE   READINESS GATES
mypod   2/2     Running   3 (43s ago)   23m   10.244.2.5   klc-worker   <none>           <none>

### NAMESPACES ###

# get shortnames of all the resources
kubectl api-resources | more

# get all namesapces
kubectl get ns

# view the current configuration used by kubectl
sysuser@ubuntudev:~$ kubectl config view

# create a pod in a non default namespace by first creating the namespace and then creating a pod in the namespace
sysuser@ubuntudev:~$ kubectl create namespace myns && kubectl -n myns run nginx --image=nginx

# use this query to get pods from all namespaces
sysuser@ubuntudev:~$ kubectl get pods --all-namespaces
OR
sysuser@ubuntudev:~$ kubectl get pods -A

# use this query to get pods from a specific non default namespace
sysuser@ubuntudev:~$ kubectl -n myns get pods -o wide

# to change the default namespace when querying
sysuser@ubuntudev:~$ kubectl config set-context --current --namespace=myns

### Deployments and ReplicaSetS ###

# create a deployment with nginx image
root@klc-control-plane:/# kubectl create deployment nginxdeployment --image=nginx --dry-run=client -o yaml | tee nginxdeployment.yaml

# copy the deployment from the control plane to host
sysuser@ubuntudev:~/git/ldk/kind-cluster$ docker cp klc-control-plane:/nginxdeployment.yaml /home/sysuser/git/ldk/kcna/kubernetes/nginxdeployment.yaml

# apply the deployment
root@klc-control-plane:/# kubectl apply -f nginxdeployment.yaml

# get deployment
root@klc-control-plane:/# kubectl get deployment

# OUTPUT
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
nginxdeployment   1/1     1            1           13s

# deployments automatically create ReplicaSetS
root@klc-control-plane:/# kubectl get replicaset -o wide

# OUTPUT
NAME                        DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR
nginxdeployment-6fd49c696   1         1         1       47s   nginx        nginx    app=nginxdeployment,pod-template-hash=6fd49c696

# get pods pods
root@klc-control-plane:/# kubectl get pods -o wide

# OUTPUT
NAME                              READY   STATUS    RESTARTS   AGE    IP           NODE          NOMINATED NODE   READINESS GATES
nginxdeployment-6fd49c696-k946p   1/1     Running   0          108s   10.244.2.3   klc-worker2   <none>           <none>

# get rollout history for deployments
root@klc-control-plane:/# kubectl rollout history deployment/nginxdeployment

# OUTPUT
REVISION  CHANGE-CAUSE
1         <none>

# annotate deployment history
root@klc-control-plane:/# kubectl annotate deployment/nginxdeployment kubernetes.io/change-cause="initial deployment"

# get rollout deployment history
root@klc-control-plane:/# kubectl rollout history deployment/nginxdeployment

# OUTPUT
deployment.apps/nginxdeployment
REVISION  CHANGE-CAUSE
1         initial deployment

# increase the number of replicas and watch the progress
root@klc-control-plane:/# kubectl scale deployment/nginxdeployment --replicas 4; watch kubectl get pods -o wide

# output
NAME                              READY   STATUS    RESTARTS   AGE     IP           NODE         NOMINATED NODE   READINESS GATES
nginxdeployment-6fd49c696-b57pt   1/1     Running   0          2m41s   10.244.1.5   klc-worker   <none>           <none>
nginxdeployment-6fd49c696-l6hh2   1/1     Running   0          2m41s   10.244.1.4   klc-worker   <none>           <none>
nginxdeployment-6fd49c696-ntl2w   1/1     Running   0          2m41s   10.244.1.6   klc-worker   <none>           <none>
nginxdeployment-6fd49c696-sjvh2   1/1     Running   0          2m59s   10.244.1.2   klc-worker   <none>           <none>

root@klc-control-plane:/# kubectl get deployment -o wide

# output
NAME              READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR
nginxdeployment   4/4     4            4           12m   nginx        nginx    app=nginxdeployment

# edit the deployment to change the number of replicas to 6
root@klc-control-plane:/# nano nginxdeployment.yaml

# apply changes
root@klc-control-plane:/# kubectl apply -f nginxdeployment.yaml

# output
deployment.apps/nginxdeployment configured

# get deployment
root@klc-control-plane:/# kubectl get deployment -o wide

# output
NAME              READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR
nginxdeployment   6/6     6            6           14m   nginx        nginx    app=nginxdeployment

# rollout history is not affected at this point
root@klc-control-plane:/# kubectl rollout history deployment/nginxdeployment

# output
deployment.apps/nginxdeployment
REVISION  CHANGE-CAUSE
1         initial deployment

# get the applied deployment for nginxdeployment
root@klc-control-plane:/# kubectl get deployment/nginxdeployment -o yaml | tee nginxdeployment-applied.yaml

# copy the file to localhost
sysuser@ubuntudev:~/git/ldk$ docker cp klc-control-plane:/nginxdeployment-applied.yaml /home/sysuser/git/ldk/kcna/kubernetes/nginxdeployment-applied.yaml

# Change the version of nginx in the original deployment
root@klc-control-plane:/# nano nginxdeployment.yaml

# copy the yaml to host
sysuser@ubuntudev:~/git/ldk$ docker cp klc-control-plane:/nginxdeployment.yaml /home/sysuser/git/ldk/kcna/kubernetes/nginxdeployment-stable.yaml

# apply the changes and watch the rollout
root@klc-control-plane:/# kubectl apply -f nginxdeployment.yaml && kubectl rollout status deployment/nginxdeployment

# OUTPUT
deployment.apps/nginxdeployment configured
Waiting for deployment "nginxdeployment" rollout to finish: 0 out of 20 new replicas have been updated...
Waiting for deployment "nginxdeployment" rollout to finish: 5 out of 20 new replicas have been updated...
Waiting for deployment "nginxdeployment" rollout to finish: 10 out of 20 new replicas have been updated...
.
.
Waiting for deployment "nginxdeployment" rollout to finish: 11 out of 20 new replicas have been updated...
.
Waiting for deployment "nginxdeployment" rollout to finish: 12 out of 20 new replicas have been updated...
.
.
.
Waiting for deployment "nginxdeployment" rollout to finish: 18 out of 20 new replicas have been updated...
Waiting for deployment "nginxdeployment" rollout to finish: 19 out of 20 new replicas have been updated...

Waiting for deployment "nginxdeployment" rollout to finish: 5 old replicas are pending termination...
.
Waiting for deployment "nginxdeployment" rollout to finish: 4 old replicas are pending termination...
.
.
Waiting for deployment "nginxdeployment" rollout to finish: 2 old replicas are pending termination...
Waiting for deployment "nginxdeployment" rollout to finish: 1 old replicas are pending termination...
.
Waiting for deployment "nginxdeployment" rollout to finish: 15 of 20 updated replicas are available...
Waiting for deployment "nginxdeployment" rollout to finish: 15 of 20 updated replicas are available...
Waiting for deployment "nginxdeployment" rollout to finish: 16 of 20 updated replicas are available...
Waiting for deployment "nginxdeployment" rollout to finish: 17 of 20 updated replicas are available...
Waiting for deployment "nginxdeployment" rollout to finish: 17 of 20 updated replicas are available...
Waiting for deployment "nginxdeployment" rollout to finish: 18 of 20 updated replicas are available...
Waiting for deployment "nginxdeployment" rollout to finish: 19 of 20 updated replicas are available...
deployment "nginxdeployment" successfully rolled out

# annotatethe history
root@klc-control-plane:/# kubectl annotate deployment/nginxdeployment kubernetes.io/change-cause="change image to nginx stable"

# get the history
root@klc-control-plane:/# kubectl rollout history deployment/nginxdeployment

# OUTPUT
REVISION  CHANGE-CAUSE
3         initial deployment
4         change image to nginx stable

# imperative change to deployment
root@klc-control-plane:/# kubectl set image deployment/nginxdeployment nginx=nginx:alpine && kubectl rollout status deployment/nginxdeployment

# incorrect tag to watch for failures
root@klc-control-plane:/# kubectl set image deployment/nginxdeployment nginx=nginx:xyzzz

# annotate the failure
root@klc-control-plane:/# kubectl annotate deployment/nginxdeployment kubernetes.io/change-cause="bad version"

# describe the deployment
root@klc-control-plane:/# kubectl describe deployment/nginxdeployment

# OUTPUT
Name:                   nginxdeployment
Namespace:              default
CreationTimestamp:      Sat, 07 Feb 2026 20:02:09 +0000
Labels:                 app=nginxdeployment
Annotations:            deployment.kubernetes.io/revision: 9
                        kubernetes.io/change-cause: bad version
Selector:               app=nginxdeployment
Replicas:               8 desired | 4 updated | 10 total | 6 available | 4 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginxdeployment
  Containers:
   nginx:
    Image:         nginx:xyzzz
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    ReplicaSetUpdated
OldReplicaSets:  nginxdeployment-6fd49c696 (0/0 replicas created), nginxdeployment-7b48fbd75 (6/6 replicas created), nginxdeployment-64d46c7cf9 (0/0 replicas created)
NewReplicaSet:   nginxdeployment-595c6ddcbf (4/4 replicas created)
Events:
  Type    Reason             Age                   From                   Message
  ----    ------             ----                  ----                   -------
  Normal  ScalingReplicaSet  19m                   deployment-controller  Scaled up replica set nginxdeployment-6fd49c696 from 0 to 6
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled up replica set nginxdeployment-6fd49c696 from 6 to 8
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled up replica set nginxdeployment-7b48fbd75 from 0 to 2
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled down replica set nginxdeployment-6fd49c696 from 8 to 6
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled up replica set nginxdeployment-7b48fbd75 from 2 to 4
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled down replica set nginxdeployment-6fd49c696 from 6 to 5
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled up replica set nginxdeployment-7b48fbd75 from 4 to 5
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled down replica set nginxdeployment-6fd49c696 from 5 to 4
  Normal  ScalingReplicaSet  17m                   deployment-controller  Scaled up replica set nginxdeployment-7b48fbd75 from 5 to 6
  Normal  ScalingReplicaSet  4m11s (x54 over 17m)  deployment-controller  (combined from similar events): Scaled down replica set nginxdeployment-595c6ddcbf from 4 to 0

# rollback the change to the deployment
root@klc-control-plane:/# kubectl rollout undo deployment/nginxdeployment

# get history
root@klc-control-plane:/# kubectl rollout history deployment/nginxdeployment

# OUTPUT
REVISION  CHANGE-CAUSE
4         alpine version
5         alpine version
9         bad version
10        alpine version

# rollback to a specific version
root@klc-control-plane:/# kubectl rollout undo deployment/nginxdeployment --to-revision=4 && kubectl rollout status deployment/nginxdeployment

##### combine operations ####

# create different yaml files for each type of image including bad image and apply each and annotate

# command to apply initial deployment with no image tag
root@klc-control-plane:/# kubectl apply -f nginxdeployment.yaml && kubectl annotate deployment/nginxdeployment kubernetes.io/change-cause="initial deployment" && kubectl rollout status deployment/nginxdeployment

# command to apply stable deployment
root@klc-control-plane:/# kubectl apply -f nginxdeployment-stable.yaml && kubectl annotate deployment/nginxdeployment kubernetes.io/change-cause="stable deployment" && kubectl rollout status deployment/nginxdeployment

# command to apply alpine deployment
root@klc-control-plane:/# kubectl apply -f nginxdeployment-alpine.yaml && kubectl annotate deployment/nginxdeployment kubernetes.io/change-cause="alpine deployment" && kubectl rollout status deployment/nginxdeployment

# bad deployment
root@klc-control-plane:/# kubectl apply -f nginxdeployment-bad.yaml && kubectl annotate deployment/nginxdeployment kubernetes.io/change-cause="bad deployment"

# history
root@klc-control-plane:/# kubectl rollout history deployment/nginxdeployment

# OUTPUT
deployment.apps/nginxdeployment
REVISION  CHANGE-CAUSE
1         initial deployment
2         stable deployment
3         alpine deployment
4         bad deployment

# rollback
root@klc-control-plane:/# kubectl rollout undo deployment/nginxdeployment

# OUTPUT
REVISION  CHANGE-CAUSE
1         initial deployment
2         stable deployment
4         bad deployment
5         alpine deployment

### ClusterIP ###

# Running the tests on host

# get a yaml for an nginx deployment with 3 replicas
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl create deployment nginxdep --image=spurin/nginx-debug --port=80 --replicas=3 -o yaml --dry-run=client | tee nginxdep.yaml

# apply the deployment
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl apply -f nginxdep.yaml

# get a yaml to expose the deployment. This creates a service. If no type is mentioned, it will be a clusterIP
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl expose deployment/nginxdep --name=nginxsvc --dry-run=client -o yaml | tee nginxsvc.yaml

# apply the service
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl apply -f nginxsvc.yaml

# output
service/nginxsvc created

# get the service
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl get svc

# output
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1      <none>        443/TCP   18h
nginxsvc     ClusterIP   10.96.119.87   <none>        80/TCP    28s

# get the endpoints
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl get endpointSlice

# output
NAME             ADDRESSTYPE   PORTS   ENDPOINTS                          AGE
kubernetes       IPv4          6443    172.18.0.3                         18h
nginxsvc-4mvl2   IPv4          80      10.244.2.6,10.244.1.6,10.244.2.7   3m17s

# get service description
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl describe service/nginxsvc

# output
Name:                     nginxsvc
Namespace:                default
Labels:                   app=nginxdep
Annotations:              <none>
Selector:                 app=nginxdep
Type:                     ClusterIP
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.96.119.87
IPs:                      10.96.119.87
Port:                     <unset>  80/TCP
TargetPort:               80/TCP
Endpoints:                10.244.2.6:80,10.244.1.6:80,10.244.2.7:80
Session Affinity:         None
Internal Traffic Policy:  Cluster
Events:                   <none>

# run curl to the endpoints from the control plane. port forwarding is not enabled yet
root@klc-control-plane:/# curl 10.244.2.6

# output
<!DOCTYPE html>
<body>
<p><em>Hostname: nginxdep-588fb5967c-tkbnt</em></p>
<p><em>IP Address: 10.244.2.6:80</em></p>
<p><em>URL: /</em></p>
<p><em>Request Method: GET</em></p>
<p><em>Request ID: 362911430815223af049018dfa951655</em></p>
</body>
</html>

# port forward to 8080 on the host so that we can curl the endpoints from the host using localhost:8080
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl port-forward service/nginxsvc 8080:80

# create curlpod.yaml
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl run curlpod --dry-run=client -o yaml --image=curlimages/curl --restart=Never --command -- sh -c "sleep infinity" | tee curlpod.yaml

# apply the pod yaml
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl apply -f curlpod.yaml

# shell into pod
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/clusterip$ kubectl exec -it curlpod -- sh

# run the following command from the curlpod. this will run curl every 2 seconds
# <servicename>.<namespace>.svc.cluster.local
~ $ watch curl nginxsvc.default.svc.cluster.local

# output. most importantly, the hostname is going to change between different pods (there are 3 replicas)
Every 2.0s: curl nginxsvc.default.svc.cluster.local                                                                                                                               2026-02-08 15:30:28

<!DOCTYPE html>
<body>
<p><em>Hostname: nginxdep-588fb5967c-d257p</em></p>
<p><em>IP Address: 10.244.2.7:80</em></p>
<p><em>URL: /</em></p>
<p><em>Request Method: GET</em></p>
<p><em>Request ID: 7fecb354e76997d2fefd938368254699</em></p>
</body>
</html>

# get the dns names and the dns server
~ $ cat /etc/resolv.conf

# output
search default.svc.cluster.local svc.cluster.local cluster.local
nameserver 10.96.0.10
options ndots:5

# this is valid
~ $ curl nginxsvc

##### NodePort ####

# delete existing clusterip service if running
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/nodeport$ kubectl delete svc/nginxsvc --now

# create a nodeport service yaml from deployment/nginxdep
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/nodeport$ kubectl expose deployment/nginxdep --name=nginxnp --dry-run=client -o yaml --type=NodePort | tee nginxnp.yaml

# apply the yaml
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/nodeport$ kubectl apply -f nginxnp.yaml

# get the services
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/nodeport$ kubectl get svc -o wide

# output
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        19h   <none>
nginxnp      NodePort    10.96.204.212   <none>        80:30732/TCP   9s    app=nginxdep

# get the nodes
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/nodeport$ kubectl get nodes -o wide

NAME                STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME
klc-control-plane   Ready    control-plane   19h   v1.35.0   172.18.0.3    <none>        Debian GNU/Linux 12 (bookworm)   6.12.67-linuxkit   containerd://2.2.0
klc-worker          Ready    <none>          19h   v1.35.0   172.18.0.4    <none>        Debian GNU/Linux 12 (bookworm)   6.12.67-linuxkit   containerd://2.2.0
klc-worker2         Ready    <none>          19h   v1.35.0   172.18.0.2    <none>        Debian GNU/Linux 12 (bookworm)   6.12.67-linuxkit   containerd://2.2.0

# curl from controlplane. this should work
root@klc-control-plane:/# curl 172.18.0.2:30732

# load balancer #

# run the command to create load balancer service from the deployment
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/loadbalancer$ kubectl expose deployment/nginxdep --dry-run=client -o yaml --port 8080 --target-port 80 --name=nginxlb --type=LoadBalancer | tee nginxlb.yaml

# apply the load balancer service
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/loadbalancer$ kubectl apply -f nginxlb.yaml

# get svc
sysuser@ubuntudev:~/git/ldk/kcna/kubernetes/loadbalancer$ kubectl get svc

# output
NAME         TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
kubernetes   ClusterIP      10.96.0.1      <none>        443/TCP          4m11s
nginxlb      LoadBalancer   10.96.75.226   172.18.0.5    8080:32188/TCP   33s

